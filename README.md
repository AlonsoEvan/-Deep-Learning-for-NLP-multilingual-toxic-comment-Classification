# -Deep-Learning-for-NLP-multilingual-toxic-comment-Classification
Kaggle project

Version 2.0 of this project made a while ago.

Kaggle project

So here's the Jigsaw Multilingual Toxic Comment Classification competition! I already participated on Jigsaw Toxic Comment Classification on Kaggle, my notebook is on GitHub and Linkedin if you want to take a look. Like is predecessor, in this competition, contestants are challenged to build machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. This problem matters because one toxic comment is enough to sour an online discussion. By identifying and filtering toxic comments online, we can have a safer, more collaborative internet, leading to greater productivity and happiness. And that's very important.

In this kernel, I will explore the data. Then, I will explain and demonstrate how various deep learning models can be used to identify toxic comments with tensorflow.keras.

In this Notebook I will cover the following Deep Learning models 

Simple RNN's
LSTM's
GRU's
BI-Directional RNN's
I will also talk about seq2seq, Attention models and BERT.


Note that the aim of this notebook is not to obtained the highest score, I haven't the right computer for this nor the time. Instead, I want to fully undertand Deep Learning techniques used for NLP.
